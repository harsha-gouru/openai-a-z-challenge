{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI-to-Z Challenge: Data Acquisition (Google Colab)\n",
    "\n",
    "This notebook is designed to run in Google Colab. It handles the data acquisition for Checkpoint 1 of the OpenAI-to-Z Challenge.\n",
    "\n",
    "**Objectives:**\n",
    "1. Install necessary dependencies.\n",
    "2. Authenticate with Google Earth Engine.\n",
    "3. Fetch one Sentinel-2 scene for the Acre, Brazil region.\n",
    "4. Fetch one LiDAR tile from a specified URL.\n",
    "5. Package the downloaded data into a single `amazon_data.zip` file for easy download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q earthengine-api geemap rasterio laspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Authenticate and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "# This will trigger the authentication flow in Colab.\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "\n",
    "print(\"Earth Engine is initialized.\")\n",
    "\n",
    "# Create directories for raw data\n",
    "os.makedirs('data/raw/sentinel2', exist_ok=True)\n",
    "os.makedirs('data/raw/lidar', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Area of Interest (AOI)\n",
    "\n",
    "We'll focus on the Acre state in western Brazil, centered around coordinates **9.5°S, 70.5°W**, a region known for its geoglyphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounding box for the Acre region\n",
    "lon_min, lon_max = -72, -69\n",
    "lat_min, lat_max = -11, -8\n",
    "\n",
    "aoi = ee.Geometry.Rectangle([lon_min, lat_min, lon_max, lat_max])\n",
    "\n",
    "# Create a map to visualize the AOI (optional)\n",
    "map_aoi = geemap.Map(center=[-9.5, -70.5], zoom=7)\n",
    "map_aoi.addLayer(aoi, {'color': 'FF0000'}, 'Area of Interest')\n",
    "map_aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Search and Download a Sentinel-2 Scene\n",
    "\n",
    "We will search for a recent, low-cloud Sentinel-2 scene within our AOI and download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_collection = (\n",
    "    ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "    .filterBounds(aoi)\n",
    "    .filterDate('2023-01-01', '2023-12-31')\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
    "    .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
    ")\n",
    "\n",
    "image_list = sentinel_collection.toList(sentinel_collection.size())\n",
    "count = image_list.size().getInfo()\n",
    "\n",
    "if count > 0:\n",
    "    selected_image = ee.Image(image_list.get(0))\n",
    "    scene_id = selected_image.id().getInfo()\n",
    "    output_path = f\"data/raw/sentinel2/{scene_id.replace('/', '_')}.tif\"\n",
    "    \n",
    "    print(f\"Found {count} scenes. Downloading the least cloudy one: {scene_id}\")\n",
    "    \n",
    "    geemap.ee_export_image(\n",
    "        selected_image,\n",
    "        filename=output_path,\n",
    "        scale=10,  # 10m resolution for Sentinel-2\n",
    "        region=aoi,\n",
    "        file_per_band=False\n",
    "    )\n",
    "    print(f\"Download complete. File saved to: {output_path}\")\n",
    "else:\n",
    "    print(\"No scenes found matching the criteria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download LiDAR Data\n",
    "\n",
    "We will download a sample LiDAR file from the **ORNL DAAC: Dataset 1644**, which covers forest sites in the Brazilian Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, directory):\n",
    "    \"\"\"Downloads a file from a URL with a progress bar into a directory.\"\"\"\" \n",
    "    filename = os.path.join(directory, url.split('/')[-1])\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        with open(filename, 'wb') as f, tqdm(\n",
    "            desc=filename.split('/')[-1],\n",
    "            total=total_size,\n",
    "            unit='iB',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as bar:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                size = f.write(chunk)\n",
    "                bar.update(size)\n",
    "        print(f\"Successfully downloaded {filename}\")\n",
    "        return filename\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "        return None\n",
    "\n",
    "# URL for a known LiDAR dataset in the Brazilian Amazon region from ORNL DAAC.\n",
    "lidar_url = \"https://daac.ornl.gov/daacdata/cms/LiDAR_Forest_Inventory_Brazil/data/FLB_7006_20140728_131235.laz\"\n",
    "lidar_filename_path = os.path.join('data/raw/lidar', lidar_url.split('/')[-1])\n",
    "\n",
    "print(f\"Preparing to download LiDAR data from: {lidar_url}\")\n",
    "download_file(lidar_url, 'data/raw/lidar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Package Data for Download\n",
    "\n",
    "This final step will zip the contents of the `data/raw` directory into a single file named `amazon_data.zip`. You can then download this file from the Colab file explorer (the folder icon on the left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_directory(folder_path, zip_path):\n",
    "    \"\"\"Zips the contents of an entire folder.\"\"\"\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file), \n",
    "                           os.path.relpath(os.path.join(root, file), \n",
    "                                           os.path.join(folder_path, '..')))\n",
    "    print(f\"Successfully created zip file at {zip_path}\")\n",
    "\n",
    "zip_directory('data/raw', 'amazon_data.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "1. Find `amazon_data.zip` in the file explorer panel on the left.\n",
    "2. Right-click on it and select \"Download\".\n",
    "3. Unzip the file on your local machine.\n",
    "4. Proceed with the `01_checkpoint_1_analysis.ipynb` notebook locally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
