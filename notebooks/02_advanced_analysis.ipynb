{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI-to-Z Challenge: Advanced Analysis\n",
    "\n",
    "This notebook builds on Checkpoint 1. Our goal is to refine the analysis pipeline to get more meaningful results from the OpenAI vision model.\n",
    "\n",
    "**Objectives:**\n",
    "1. Enhance the Digital Terrain Model (DTM) to highlight subtle features.\n",
    "2. Tile the DTM into smaller, manageable chunks for analysis.\n",
    "3. Use a more sophisticated prompt to guide the OpenAI model.\n",
    "4. Process the results and visualize them on an interactive map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T03:57:31.265178Z",
     "iopub.status.busy": "2025-06-30T03:57:31.264859Z",
     "iopub.status.idle": "2025-06-30T03:57:31.882536Z",
     "shell.execute_reply": "2025-06-30T03:57:31.882288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and OpenAI client initialized.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import numpy as np\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import json\n",
    "import cv2 # OpenCV for image processing\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from shapely.geometry import box\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "print(\"Libraries imported and OpenAI client initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load DTM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T03:57:31.897045Z",
     "iopub.status.busy": "2025-06-30T03:57:31.896905Z",
     "iopub.status.idle": "2025-06-30T03:57:31.901069Z",
     "shell.execute_reply": "2025-06-30T03:57:31.900863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM file loaded successfully: /Users/shg/Projects/openai-a-z-challenge/data/raw/TAL_A01_2018/TAL_A01_2018_DTM/TAL01L0001C0002.grd\n",
      "  - CRS: None\n",
      "  - Bounds: BoundingBox(left=611108.0, bottom=8866715.0, right=612109.0, top=8867716.0)\n"
     ]
    }
   ],
   "source": [
    "dtm_raster_path = '/Users/shg/Projects/openai-a-z-challenge/data/raw/TAL_A01_2018/TAL_A01_2018_DTM/TAL01L0001C0002.grd'\n",
    "\n",
    "try:\n",
    "    with rasterio.open(dtm_raster_path) as src:\n",
    "        dtm_profile = src.profile\n",
    "        dtm_bounds = src.bounds\n",
    "        dtm_crs = src.crs\n",
    "        print(f\"DTM file loaded successfully: {dtm_raster_path}\")\n",
    "        print(f\"  - CRS: {dtm_crs}\")\n",
    "        print(f\"  - Bounds: {dtm_bounds}\")\n",
    "except rasterio.errors.RasterioIOError as e:\n",
    "    print(f\"Error loading DTM file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Enhancement and Tiling\n",
    "\n",
    "To improve the model's ability to detect subtle features, we will first enhance the contrast of the DTM image using histogram equalization. Then, we'll break the large DTM into smaller, overlapping tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T03:57:31.902116Z",
     "iopub.status.busy": "2025-06-30T03:57:31.902055Z",
     "iopub.status.idle": "2025-06-30T03:57:31.929331Z",
     "shell.execute_reply": "2025-06-30T03:57:31.929116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 9 tiles from /Users/shg/Projects/openai-a-z-challenge/data/raw/TAL_A01_2018/TAL_A01_2018_DTM/TAL01L0001C0002.grd\n"
     ]
    }
   ],
   "source": [
    "def enhance_image(image_data):\n",
    "    \"\"\"Applies histogram equalization to enhance image contrast.\"\"\"\n",
    "    # Normalize to 0-255 range for 8-bit image processing\n",
    "    normalized = cv2.normalize(image_data, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    # Apply histogram equalization\n",
    "    equalized = cv2.equalizeHist(normalized)\n",
    "    return equalized\n",
    "\n",
    "def tile_raster(raster_path, tile_size=(512, 512), overlap=128):\n",
    "    \"\"\"Tiles a large raster into smaller, overlapping chunks.\"\"\"\n",
    "    tiles = []\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        width, height = src.width, src.height\n",
    "        stride = tile_size[0] - overlap\n",
    "        for y in range(0, height, stride):\n",
    "            for x in range(0, width, stride):\n",
    "                # Define the window for the tile\n",
    "                window = Window(x, y, tile_size[0], tile_size[1])\n",
    "                # Read the data, enhance it, and get transform for coordinates\n",
    "                tile_data = src.read(1, window=window)\n",
    "                enhanced_tile = enhance_image(tile_data)\n",
    "                tile_transform = src.window_transform(window)\n",
    "                tiles.append((enhanced_tile, tile_transform))\n",
    "    print(f\"Generated {len(tiles)} tiles from {raster_path}\")\n",
    "    return tiles\n",
    "\n",
    "# Generate tiles from our DTM\n",
    "try:\n",
    "    dtm_tiles = tile_raster(dtm_raster_path)\n",
    "except NameError:\n",
    "    print(\"DTM file not loaded, skipping tiling.\")\n",
    "    dtm_tiles = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced OpenAI API Analysis\n",
    "\n",
    "Now we'll loop through each enhanced tile and send it to the OpenAI model with a more detailed prompt. We'll ask for a structured JSON output to make the results easier to parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T03:57:31.930414Z",
     "iopub.status.busy": "2025-06-30T03:57:31.930353Z",
     "iopub.status.idle": "2025-06-30T03:57:38.452871Z",
     "shell.execute_reply": "2025-06-30T03:57:38.452230Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles:  11%|█         | 1/9 [00:00<00:05,  1.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles:  22%|██▏       | 2/9 [00:01<00:04,  1.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles:  33%|███▎      | 3/9 [00:01<00:03,  1.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles:  44%|████▍     | 4/9 [00:02<00:03,  1.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles:  56%|█████▌    | 5/9 [00:03<00:03,  1.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles:  67%|██████▋   | 6/9 [00:04<00:02,  1.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles:  78%|███████▊  | 7/9 [00:05<00:01,  1.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles:  89%|████████▉ | 8/9 [00:05<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles: 100%|██████████| 9/9 [00:06<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Analyzing Tiles: 100%|██████████| 9/9 [00:06<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Found 0 potential features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def numpy_to_base64(np_array):\n",
    "    \"\"\"Converts a NumPy array to a base64 encoded PNG image.\"\"\"\n",
    "    img = Image.fromarray(np_array, 'L') # 'L' for grayscale\n",
    "    buffered = BytesIO()\n",
    "    img.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "def analyze_tile_with_openai(image_tile):\n",
    "    \"\"\"Sends a single tile to the OpenAI API for analysis.\"\"\"\n",
    "    base64_image = numpy_to_base64(image_tile)\n",
    "    \n",
    "    MODEL = \"gpt-4o\"\n",
    "    PROMPT = \"\"\"You are an expert remote sensing archaeologist. Analyze this enhanced Digital Terrain Model (DTM) image from the Amazon rainforest. Your task is to identify potential pre-Columbian archaeological earthworks (geoglyphs).\n",
    "    \n",
    "    Look for the following patterns:\n",
    "    1.  **Geometric Shapes:** Clear geometric forms such as circles, squares, rectangles, or octagons. These may appear as ditches or embankments.\n",
    "    2.  **Linear Features:** Long, straight lines or causeways that are not consistent with modern roads or infrastructure.\n",
    "    \n",
    "    Ignore modern features like recent deforestation lines, roads, or buildings. Focus only on patterns that could be ancient.\n",
    "    \n",
    "    Respond with a JSON object. The object should contain a single key, 'features', which is a list of found objects. Each object in the list should have:\n",
    "    - 'shape': A string describing the shape (e.g., 'circle', 'rectangle', 'linear_ditch').\n",
    "    - 'center_coords': The approximate center of the feature as [x, y] coordinates, scaled from 0.0 to 1.0 (top-left is [0,0]).\n",
    "    - 'confidence': Your confidence level (Low, Medium, High) that this is a potential archaeological feature.\n",
    "    - 'description': A brief justification for your finding.\n",
    "    \n",
    "    If you find no potential features, return an empty list: {\"features\": []}.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": PROMPT},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            response_format={\"type\": \"json_object\"} # Request JSON output\n",
    "        )\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during API call: {e}\")\n",
    "        return None\n",
    "\n",
    "# Loop through tiles and analyze them\n",
    "analysis_results = []\n",
    "if dtm_tiles:\n",
    "    for i, (tile_image, tile_transform) in enumerate(tqdm(dtm_tiles, desc=\"Analyzing Tiles\")):\n",
    "        result = analyze_tile_with_openai(tile_image)\n",
    "        if result and result.get('features'):\n",
    "            for feature in result['features']:\n",
    "                analysis_results.append({\n",
    "                    \"tile_index\": i,\n",
    "                    \"transform\": tile_transform,\n",
    "                    \"feature\": feature\n",
    "                })\n",
    "print(f\"Analysis complete. Found {len(analysis_results)} potential features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process and Visualize Results\n",
    "\n",
    "Finally, we'll convert the analysis results into a GeoDataFrame and plot them on an interactive map using Folium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T03:57:38.456263Z",
     "iopub.status.busy": "2025-06-30T03:57:38.455950Z",
     "iopub.status.idle": "2025-06-30T03:57:38.464102Z",
     "shell.execute_reply": "2025-06-30T03:57:38.463554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No analysis results to display.\n"
     ]
    }
   ],
   "source": [
    "def results_to_geodataframe(results, dtm_crs):\n",
    "    \"\"\"Converts the list of analysis results to a GeoDataFrame.\"\"\"\n",
    "    records = []\n",
    "    for res in results:\n",
    "        feature = res['feature']\n",
    "        transform = res['transform']\n",
    "        # Get image coordinates from relative 0-1 scale\n",
    "        img_x = feature['center_coords'][0] * 512\n",
    "        img_y = feature['center_coords'][1] * 512\n",
    "        # Convert image coordinates to geographic coordinates\n",
    "        geo_x, geo_y = rasterio.transform.xy(transform, img_y, img_x)\n",
    "        \n",
    "        records.append({\n",
    "            'geometry': gpd.points_from_xy([geo_x], [geo_y])[0],\n",
    "            'shape': feature['shape'],\n",
    "            'confidence': feature['confidence'],\n",
    "            'description': feature['description']\n",
    "        })\n",
    "    \n",
    "    if not records:\n",
    "        return None\n",
    "        \n",
    "    gdf = gpd.GeoDataFrame(records, crs=dtm_crs)\n",
    "    return gdf\n",
    "\n",
    "# Create GeoDataFrame\n",
    "if analysis_results:\n",
    "    features_gdf = results_to_geodataframe(analysis_results, dtm_crs)\n",
    "    if features_gdf is not None:\n",
    "        # Reproject to WGS84 for Folium map\n",
    "        features_gdf_wgs84 = features_gdf.to_crs(epsg=4326)\n",
    "\n",
    "        # Create a map centered on the DTM bounds\n",
    "        center_y, center_x = (dtm_bounds.top + dtm_bounds.bottom) / 2, (dtm_bounds.left + dtm_bounds.right) / 2\n",
    "        \n",
    "        # Need to reproject center point for Folium\n",
    "        center_point_gdf = gpd.GeoDataFrame([{'geometry': gpd.points_from_xy([center_x], [center_y])[0]}], crs=dtm_crs).to_crs(epsg=4326)\n",
    "        map_center = [center_point_gdf.geometry.y[0], center_point_gdf.geometry.x[0]]\n",
    "\n",
    "        m = folium.Map(location=map_center, zoom_start=12, tiles='CartoDB positron')\n",
    "\n",
    "        # Add detected features to the map\n",
    "        for _, row in features_gdf_wgs84.iterrows():\n",
    "            folium.Marker(\n",
    "                location=[row.geometry.y, row.geometry.x],\n",
    "                popup=f\"<b>Shape:</b> {row['shape']}<br><b>Confidence:</b> {row['confidence']}<br><b>Desc:</b> {row['description']}\",\n",
    "                icon=folium.Icon(color='red', icon='info-sign')\n",
    "            ).add_to(m)\n",
    "            \n",
    "        # Add DTM boundary to map\n",
    "        bounds_poly = box(dtm_bounds.left, dtm_bounds.bottom, dtm_bounds.right, dtm_bounds.top)\n",
    "        bounds_gdf = gpd.GeoDataFrame([{'geometry': bounds_poly}], crs=dtm_crs).to_crs(epsg=4326)\n",
    "        folium.GeoJson(bounds_gdf, style_function=lambda x: {'fillColor': 'blue', 'color': 'blue'}).add_to(m)\n",
    "\n",
    "        display(m)\n",
    "    else:\n",
    "        print(\"No features were found to visualize.\")\n",
    "else:\n",
    "    print(\"No analysis results to display.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
